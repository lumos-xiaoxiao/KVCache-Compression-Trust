model_config:
  model: hf//data/maxiaoxiao/security/model/Llama-2-7b-chat-hf
  type: CHAT
  conv_template: llama-2
  model_loader: HF
  torch_dtype: FLOAT16
  trust_remote_code: true
  use_auth_token: true
  disable_exllama: false
  inject_fused_attention: true
  quant_file: null
  tokenizer_name: null
  device_map: auto
disable_sys_prompt: false
key: null
dry_run: false
advglue:
  sys: false
  demo: true
  data_file: ./data/adv-glue-plus-plus/data/vicuna.json
  out_file: ./results/adv-glue-plus-plus/${model_config.model}/vicuna-demo.json
  no_adv: false
  resume: false
  save_interval: 100
  remove_newline: false
  task:
  - sst2
  - qqp
  - mnli
adv_demonstration: null
fairness: null
machine_ethics: null
ood: null
privacy: null
stereotype: null
toxicity: null
