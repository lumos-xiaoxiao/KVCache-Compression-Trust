model_config:
  model: hf//data/maxiaoxiao/security/model/Llama-2-7b-chat-hf
  type: CHAT
  conv_template: llama-2
  model_loader: HF
  torch_dtype: FLOAT16
  trust_remote_code: true
  use_auth_token: true
  disable_exllama: false
  inject_fused_attention: true
  quant_file: null
  tokenizer_name: null
  device_map: auto
disable_sys_prompt: false
key: null
dry_run: false
advglue: null
adv_demonstration: null
fairness: null
machine_ethics: null
ood: null
privacy: null
stereotype: null
toxicity:
  data_file: ./data/toxicity/user_prompts/nontoxic.jsonl
  out_file: ./results/toxicity/user_prompts/generations/${model_config.model}/nontoxic-template-${.template}-generations.jsonl
  template: 1
  max_tokens: 150
  'n': 25
  t: 1
  save_interval: 100
  api: null
